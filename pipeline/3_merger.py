import pymongo
import time
import sys
import os
import logging
from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors, QED
from tqdm import tqdm

# --- 1. ç¯å¢ƒé…ç½® ---
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
import config

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- 2. æ•°æ®åº“è¿æ¥ ---
try:
    client = pymongo.MongoClient(config.MONGO_URI)
    
    db_raw = client[config.DB_RAW]
    col_pubchem = db_raw["raw_pubchem"]
    col_chembl = db_raw["raw_chembl"]
    col_pdb = db_raw["raw_pdb"]
    
    db_core = client["drug_core"]
    col_merged = db_core["merged_rough_data"]
    
    # ã€ä¿®å¤æ­¥éª¤ 1ã€‘å…ˆåˆ é™¤æ—§ç´¢å¼•ï¼Œé˜²æ­¢ä¹‹å‰çš„é”™è¯¯æ®‹ç•™
    try:
        col_merged.drop_index("identity.std_inchi_key_1")
        logging.info("ğŸ§¹ å·²æ¸…ç†æ—§ç´¢å¼•")
    except:
        pass # å¦‚æœç´¢å¼•æœ¬æ¥å°±ä¸å­˜åœ¨ï¼Œå¿½ç•¥æŠ¥é”™
    
    # ã€ä¿®å¤æ­¥éª¤ 2ã€‘é‡æ–°åˆ›å»ºç¨€ç–å”¯ä¸€ç´¢å¼•
    # sparse=True çš„æ„æ€æ˜¯ï¼šåªæœ‰å½“æ–‡æ¡£é‡ŒåŒ…å«è¿™ä¸ªå­—æ®µæ—¶ï¼Œæ‰æ£€æŸ¥å”¯ä¸€æ€§ã€‚ä¸åŒ…å«å°±ä¸æ£€æŸ¥ã€‚
    col_merged.create_index("identity.std_inchi_key", unique=True, sparse=True)
    col_merged.create_index("identity.primary_name")
    
    logging.info(f"ğŸ”Œ æ•°æ®åº“è¿æ¥æˆåŠŸ: {config.MONGO_URI}")

except Exception as e:
    logging.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
    sys.exit(1)


def generate_3d_conformer(mol):
    """ç”Ÿæˆ 3D æ„è±¡"""
    try:
        mol_h = Chem.AddHs(mol)
        res = AllChem.EmbedMolecule(mol_h, AllChem.ETKDG(randomSeed=42))
        if res == 0:
            AllChem.MMFFOptimizeMolecule(mol_h)
            return Chem.MolToMolBlock(mol_h), "Computed_RDKit"
    except:
        pass
    return None, "Failed"

def process_small_molecules():
    """å¤„ç†å°åˆ†å­"""
    raw_mols = list(col_pubchem.find({}))
    # è¿‡æ»¤æ‰æ²¡æœ‰ SMILES çš„æ•°æ®å†è®¡æ•°ï¼Œè®©è¿›åº¦æ¡æ›´å‡†
    valid_mols = [m for m in raw_mols if m.get("data", {}).get("isomeric_smiles")]
    
    logging.info(f"ğŸ§ª å¼€å§‹å¤„ç†å°åˆ†å­ï¼Œæœ‰æ•ˆè®°å½• {len(valid_mols)} æ¡...")

    success_count = 0
    for p_doc in tqdm(valid_mols, desc="Processing Molecules", unit="mol"):
        name = p_doc.get("query_name")
        p_data = p_doc.get("data", {})
        input_smiles = p_data.get("isomeric_smiles")

        mol = Chem.MolFromSmiles(input_smiles)
        if not mol: continue
        
        std_inchi_key = Chem.MolToInchiKey(mol)
        canonical_smiles = Chem.MolToSmiles(mol, canonical=True)
        mol_block, str_source = generate_3d_conformer(mol)

        props = {
            "mw": Descriptors.MolWt(mol),
            "logp": Descriptors.MolLogP(mol),
            "hbd": Descriptors.NumHDonors(mol),
            "hba": Descriptors.NumHAcceptors(mol),
            "tpsa": Descriptors.TPSA(mol),
            "qed": QED.qed(mol)
        }

        # èåˆ ChEMBL
        c_doc = col_chembl.find_one({"query_name": name})
        bio_targets = []
        chembl_id = None
        
        if c_doc and c_doc.get("data"):
            c_data = c_doc.get("data", {})
            if "molecule_info" in c_data:
                chembl_id = c_data["molecule_info"].get("molecule_chembl_id")
            if "bio_activities" in c_data:
                for act in c_data["bio_activities"]:
                    if act.get("standard_value") and act.get("standard_type") in ["IC50", "Ki", "Kd", "EC50"]:
                        bio_targets.append({
                            "target_id": act.get("target_chembl_id"),
                            "type": act.get("standard_type"),
                            "value": float(act.get("standard_value")),
                            "unit": act.get("standard_units")
                        })

        merged_doc = {
            "type": "Small_Molecule",
            "identity": {
                "primary_name": name,
                "std_inchi_key": std_inchi_key, # å°åˆ†å­æœ‰è¿™ä¸ªå­—æ®µ
                "ids": {
                    "pubchem_cid": p_data.get("cid"),
                    "chembl_id": chembl_id
                }
            },
            "structure": {
                "smiles_clean": canonical_smiles,
                "mol_block_3d": mol_block,
                "3d_source": str_source
            },
            "properties": props,
            "bio_activity": {
                "targets": bio_targets,
                "count": len(bio_targets)
            },
            "meta": {
                "source_pipeline": "MolNexus_V1",
                "last_updated": time.time()
            }
        }

        try:
            col_merged.update_one(
                {"identity.std_inchi_key": std_inchi_key}, 
                {"$set": merged_doc}, 
                upsert=True
            )
            success_count += 1
        except Exception as e:
            pass

    print(f"\nâœ… å°åˆ†å­å¤„ç†å®Œæˆï¼Œå…¥åº“ {success_count} æ¡ã€‚")


def process_proteins():
    """å¤„ç†è›‹ç™½è´¨"""
    raw_pdbs = list(col_pdb.find({}))
    logging.info(f"\nğŸ§¬ å¼€å§‹å¤„ç†è›‹ç™½è´¨ï¼Œå…± {len(raw_pdbs)} ä¸ªè®°å½•...")
    
    success_count = 0
    for doc in tqdm(raw_pdbs, desc="Processing Proteins ", unit="pdb"):
        pdb_id = doc.get("query_id")
        data = doc.get("data", {})
        
        info = data.get("rcsb_entry_info", {})
        struct = data.get("struct", {})
        
        merged_doc = {
            "type": "Protein_Target",
            "identity": {
                "primary_name": pdb_id,
                # ã€ä¿®å¤æ­¥éª¤ 3ã€‘è¿™é‡Œå½»åº•åˆ æ‰äº† "std_inchi_key": None
                # å› ä¸ºåªæœ‰å­—æ®µä¸å­˜åœ¨ï¼Œsparse ç´¢å¼•æ‰ä¼šå¿½ç•¥å®ƒ
                "ids": {
                    "pdb_id": pdb_id,
                }
            },
            "structure": {
                "title": struct.get("title"),
                "method": data.get("exptl", [{}])[0].get("method"),
                "resolution": info.get("resolution_combined", [None])[0]
            },
            "properties": {
                "polymer_count": info.get("polymer_entity_count_protein"),
                "atom_count": info.get("atom_count_lebedev")
            },
            "meta": {
                "source_pipeline": "MolNexus_V1",
                "last_updated": time.time()
            }
        }
        
        try:
            col_merged.update_one(
                {"identity.primary_name": pdb_id},
                {"$set": merged_doc},
                upsert=True
            )
            success_count += 1
        except Exception as e:
            logging.error(f"Error saving {pdb_id}: {e}")
        
    print(f"\nâœ… è›‹ç™½è´¨å¤„ç†å®Œæˆï¼Œå…¥åº“ {success_count} æ¡ã€‚")

if __name__ == "__main__":
    print(f"{'='*30} MolNexus Merger å¯åŠ¨ {'='*30}")
    process_small_molecules()
    process_proteins()
    print(f"\nğŸ‰ å…¨éƒ¨æ¸…æ´—ä¸èåˆå®Œæ¯•ï¼")

